{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "authorship_tag": "ABX9TyN2fBThgo8wJQn6Xf6V6crC",
      "provenance": []
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Convolutional Neural Network",
      "metadata": {
        "id": "3DR-eO17geWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Importing the libraries",
      "metadata": {
        "id": "EMefrVPCg-60"
      }
    },
    {
      "cell_type": "code",
      "source": "import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
      "metadata": {
        "executionInfo": {
          "elapsed": 4097,
          "status": "ok",
          "timestamp": 1727869696217,
          "user": {
            "displayName": "Hadelin de Ponteves",
            "userId": "15047218817161520419"
          },
          "user_tz": -240
        },
        "id": "sCV30xyVhFbE"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "## Part 1 - Data Preprocessing",
      "metadata": {
        "id": "oxQxCBWyoGPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Preprocessing the Training set",
      "metadata": {
        "id": "MvE-heJNo3GG"
      }
    },
    {
      "cell_type": "code",
      "source": "IMG_SIZE = (150, 150)\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    'dataset/training_set',\n    target_size=IMG_SIZE,\n    batch_size=32,\n    class_mode='binary'\n)\n\n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 404,
          "status": "ok",
          "timestamp": 1727869709542,
          "user": {
            "displayName": "Hadelin de Ponteves",
            "userId": "15047218817161520419"
          },
          "user_tz": -240
        },
        "id": "0koUcJMJpEBD",
        "outputId": "12d2b27d-22f4-4af3-833f-5ca0cd00336c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": "### Preprocessing the Test set",
      "metadata": {
        "id": "mrCMmGw9pHys"
      }
    },
    {
      "cell_type": "code",
      "source": "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n    'dataset/test_set',\n    target_size=IMG_SIZE,\n    batch_size=32,\n    class_mode='binary'\n)\n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 432,
          "status": "ok",
          "timestamp": 1727869749266,
          "user": {
            "displayName": "Hadelin de Ponteves",
            "userId": "15047218817161520419"
          },
          "user_tz": -240
        },
        "id": "SH4WzfOhpKc3",
        "outputId": "eefdf71b-6707-4ad0-99db-04603d820197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "## Part 2 - Building the CNN",
      "metadata": {
        "id": "af8O4l90gk7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Initialising the CNN",
      "metadata": {
        "id": "ces1gXY2lmoX"
      }
    },
    {
      "cell_type": "code",
      "source": "model = models.Sequential()",
      "metadata": {},
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "### Step 1 - Convolution",
      "metadata": {
        "id": "u5YJj_XMl5LF"
      }
    },
    {
      "cell_type": "code",
      "source": "# Add the convolutional \nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)))  # First Conv Layer",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 415,
          "status": "ok",
          "timestamp": 1727869820333,
          "user": {
            "displayName": "Hadelin de Ponteves",
            "userId": "15047218817161520419"
          },
          "user_tz": -240
        },
        "id": "XPzPrMckl-hV",
        "outputId": "329e2f0a-ec6c-4b72-c6ad-000f7ba7cda6"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "### Step 2 - Pooling",
      "metadata": {
        "id": "tf87FpvxmNOJ"
      }
    },
    {
      "cell_type": "code",
      "source": "# Add pooling layers\nmodel.add(layers.MaxPooling2D((2, 2)))  # MaxPooling Layer",
      "metadata": {
        "executionInfo": {
          "elapsed": 637,
          "status": "ok",
          "timestamp": 1727869823557,
          "user": {
            "displayName": "Hadelin de Ponteves",
            "userId": "15047218817161520419"
          },
          "user_tz": -240
        },
        "id": "ncpqPl69mOac"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "### Adding a second convolutional layer",
      "metadata": {
        "id": "xaTOgD8rm4mU"
      }
    },
    {
      "cell_type": "code",
      "source": "model.add(layers.Conv2D(64, (3, 3), activation='relu'))  # Second Conv Layer\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))  # Third Conv Layer\nmodel.add(layers.MaxPooling2D((2, 2)))",
      "metadata": {
        "executionInfo": {
          "elapsed": 406,
          "status": "ok",
          "timestamp": 1727869826266,
          "user": {
            "displayName": "Hadelin de Ponteves",
            "userId": "15047218817161520419"
          },
          "user_tz": -240
        },
        "id": "i_-FZjn_m8gk"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "### Step 3 - Flattening",
      "metadata": {
        "id": "tmiEuvTunKfk"
      }
    },
    {
      "cell_type": "code",
      "source": "model.add(layers.Flatten())",
      "metadata": {
        "executionInfo": {
          "elapsed": 617,
          "status": "ok",
          "timestamp": 1727869828932,
          "user": {
            "displayName": "Hadelin de Ponteves",
            "userId": "15047218817161520419"
          },
          "user_tz": -240
        },
        "id": "6AZeOGCvnNZn"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": "### Step 4 - Full Connection",
      "metadata": {
        "id": "dAoSECOm203v"
      }
    },
    {
      "cell_type": "code",
      "source": "model.add(layers.Dense(128, activation='relu'))\n# Add a dropout layer to reduce overfitting\nmodel.add(layers.Dropout(0.5))",
      "metadata": {
        "executionInfo": {
          "elapsed": 384,
          "status": "ok",
          "timestamp": 1727869831487,
          "user": {
            "displayName": "Hadelin de Ponteves",
            "userId": "15047218817161520419"
          },
          "user_tz": -240
        },
        "id": "8GtmUlLd26Nq"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "### Step 5 - Output Layer",
      "metadata": {
        "id": "yTldFvbX28Na"
      }
    },
    {
      "cell_type": "code",
      "source": "# Output layer with sigmoid activation (binary classification: dog or cat)\nmodel.add(layers.Dense(1, activation='sigmoid'))",
      "metadata": {
        "executionInfo": {
          "elapsed": 433,
          "status": "ok",
          "timestamp": 1727870028191,
          "user": {
            "displayName": "Hadelin de Ponteves",
            "userId": "15047218817161520419"
          },
          "user_tz": -240
        },
        "id": "1p_Zj1Mc3Ko_"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": "## Part 3 - Training the CNN",
      "metadata": {
        "id": "D6XkI90snSDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Compiling the CNN",
      "metadata": {
        "id": "vfrFQACEnc6i"
      }
    },
    {
      "cell_type": "code",
      "source": "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])",
      "metadata": {
        "executionInfo": {
          "elapsed": 416,
          "status": "ok",
          "timestamp": 1727870049309,
          "user": {
            "displayName": "Hadelin de Ponteves",
            "userId": "15047218817161520419"
          },
          "user_tz": -240
        },
        "id": "NALksrNQpUlJ"
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "### Training the CNN on the Training set and evaluating it on the Test set",
      "metadata": {
        "id": "ehS-v3MIpX2h"
      }
    },
    {
      "cell_type": "code",
      "source": "history = model.fit(\n    train_generator,\n    steps_per_epoch=250, \n    epochs=10, \n    validation_data=validation_generator,\n    validation_steps=10) ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 53294,
          "status": "ok",
          "timestamp": 1727870127564,
          "user": {
            "displayName": "Hadelin de Ponteves",
            "userId": "15047218817161520419"
          },
          "user_tz": -240
        },
        "id": "XUj1W4PJptta",
        "outputId": "6af733bf-672f-4229-efe2-f0847b4118e7",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 87s 345ms/step - loss: 0.6940 - accuracy: 0.5300 - val_loss: 0.6425 - val_accuracy: 0.6375\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 85s 339ms/step - loss: 0.6574 - accuracy: 0.6165 - val_loss: 0.6350 - val_accuracy: 0.6500\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 70s 281ms/step - loss: 0.6334 - accuracy: 0.6466 - val_loss: 0.5884 - val_accuracy: 0.7094\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 85s 339ms/step - loss: 0.5946 - accuracy: 0.6911 - val_loss: 0.5790 - val_accuracy: 0.6969\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 67s 266ms/step - loss: 0.5644 - accuracy: 0.7103 - val_loss: 0.5176 - val_accuracy: 0.7469\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 82s 328ms/step - loss: 0.5304 - accuracy: 0.7337 - val_loss: 0.4871 - val_accuracy: 0.7781\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 78s 313ms/step - loss: 0.5074 - accuracy: 0.7495 - val_loss: 0.4997 - val_accuracy: 0.7812\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 69s 277ms/step - loss: 0.4748 - accuracy: 0.7701 - val_loss: 0.4942 - val_accuracy: 0.7625\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 71s 283ms/step - loss: 0.4478 - accuracy: 0.7912 - val_loss: 0.5183 - val_accuracy: 0.7719\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 78s 312ms/step - loss: 0.4406 - accuracy: 0.7918 - val_loss: 0.4636 - val_accuracy: 0.7812\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": "## Part 4 - Making a single prediction",
      "metadata": {
        "id": "U3PZasO0006Z"
      }
    },
    {
      "cell_type": "code",
      "source": "single_image_dir = 'dataset/single_prediction'\n\nfor img_name in os.listdir(single_image_dir):\n    img_path = os.path.join(single_image_dir, img_name)\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\n    img_array = tf.keras.preprocessing.image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0) / 255.0\n\n    prediction = model.predict(img_array)\n    if prediction[0] > 0.5:\n        print(f'{img_name}: Dog')\n    else:\n        print(f'{img_name}: Cat')\n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 553,
          "status": "ok",
          "timestamp": 1727870175470,
          "user": {
            "displayName": "Hadelin de Ponteves",
            "userId": "15047218817161520419"
          },
          "user_tz": -240
        },
        "id": "gsSiWEJY1BPB",
        "outputId": "3a1eabe0-aa2b-48ac-cc6e-a32906dbf08e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 11ms/step\n",
            "cat_or_dog_1.jpg: Dog\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "cat_or_dog_2.jpg: Cat\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "cat_or_dog_3.jpg: Cat\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "cat_or_dog_4.jpg: Cat\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "cat_or_dog_5.jpg: Dog\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "cat_or_dog_6.jpg: Dog\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cat_or_dog_7.jpg: Cat\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "cat_or_dog_8.jpg: Dog\n"
          ]
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": "My Github link: https://github.com/Rui6789/Convolutional-Neural-Network-CNN-for-Image-Classification",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 402,
          "status": "ok",
          "timestamp": 1727870200094,
          "user": {
            "displayName": "Hadelin de Ponteves",
            "userId": "15047218817161520419"
          },
          "user_tz": -240
        },
        "id": "ED9KB3I54c1i",
        "outputId": "7f130fcb-f755-463d-c743-b9d3565b5e97"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "My Medium link: https://medium.com/@mma1_65597/convolutional-neural-network-for-dog-vs-cat-image-classification-79a2af9717a3",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}